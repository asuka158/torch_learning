{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Pytorch加载数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① Pytorch中加载数据需要Dataset、Dataloader。\n",
    "\n",
    " - Dataset提供一种方式去获取每个数据及其对应的label，告诉我们总共有多少个数据。\n",
    " - Dataloader为后面的网络提供不同的数据形式，它将一批一批数据进行一个打包。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 常用数据集两种形式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① 常用的第一种数据形式，文件夹的名称是它的label。\n",
    "\n",
    "② 常用的第二种形式，lebel为文本格式，文本名称为图片名称，文本中的内容为对应的label。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Dataset in module torch.utils.data.dataset:\n",
      "\n",
      "class Dataset(typing.Generic)\n",
      " |  An abstract class representing a :class:`Dataset`.\n",
      " |  \n",
      " |  All datasets that represent a map from keys to data samples should subclass\n",
      " |  it. All subclasses should overwrite :meth:`__getitem__`, supporting fetching a\n",
      " |  data sample for a given key. Subclasses could also optionally overwrite\n",
      " |  :meth:`__len__`, which is expected to return the size of the dataset by many\n",
      " |  :class:`~torch.utils.data.Sampler` implementations and the default options\n",
      " |  of :class:`~torch.utils.data.DataLoader`. Subclasses could also\n",
      " |  optionally implement :meth:`__getitems__`, for speedup batched samples\n",
      " |  loading. This method accepts list of indices of samples of batch and returns\n",
      " |  list of samples.\n",
      " |  \n",
      " |  .. note::\n",
      " |    :class:`~torch.utils.data.DataLoader` by default constructs an index\n",
      " |    sampler that yields integral indices.  To make it work with a map-style\n",
      " |    dataset with non-integral indices/keys, a custom sampler must be provided.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Dataset\n",
      " |      typing.Generic\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      " |  \n",
      " |  __getitem__(self, index) -> +T_co\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      " |  \n",
      " |  __parameters__ = (+T_co,)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from typing.Generic:\n",
      " |  \n",
      " |  __class_getitem__(params) from builtins.type\n",
      " |  \n",
      " |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      " |      This method is called when a class is subclassed.\n",
      " |      \n",
      " |      The default implementation does nothing. It may be\n",
      " |      overridden to extend subclasses.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "help(Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSource:\u001b[0m        \n",
      "\u001b[0;32mclass\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGeneric\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mT_co\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34mr\"\"\"An abstract class representing a :class:`Dataset`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    All datasets that represent a map from keys to data samples should subclass\u001b[0m\n",
      "\u001b[0;34m    it. All subclasses should overwrite :meth:`__getitem__`, supporting fetching a\u001b[0m\n",
      "\u001b[0;34m    data sample for a given key. Subclasses could also optionally overwrite\u001b[0m\n",
      "\u001b[0;34m    :meth:`__len__`, which is expected to return the size of the dataset by many\u001b[0m\n",
      "\u001b[0;34m    :class:`~torch.utils.data.Sampler` implementations and the default options\u001b[0m\n",
      "\u001b[0;34m    of :class:`~torch.utils.data.DataLoader`. Subclasses could also\u001b[0m\n",
      "\u001b[0;34m    optionally implement :meth:`__getitems__`, for speedup batched samples\u001b[0m\n",
      "\u001b[0;34m    loading. This method accepts list of indices of samples of batch and returns\u001b[0m\n",
      "\u001b[0;34m    list of samples.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    .. note::\u001b[0m\n",
      "\u001b[0;34m      :class:`~torch.utils.data.DataLoader` by default constructs an index\u001b[0m\n",
      "\u001b[0;34m      sampler that yields integral indices.  To make it work with a map-style\u001b[0m\n",
      "\u001b[0;34m      dataset with non-integral indices/keys, a custom sampler must be provided.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT_co\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Subclasses of Dataset should implement __getitem__.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# def __getitems__(self, indices: List) -> List[T_co]:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Not implemented to prevent false-positives in fetcher check in\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# torch.utils.data._utils.fetch._MapDatasetFetcher\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__add__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Dataset[T_co]\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"ConcatDataset[T_co]\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mConcatDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# No `def __len__(self)` default?\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# See NOTE [ Lack of Default `__len__` in Python Abstract Base Classes ]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# in pytorch/torch/utils/data/sampler.py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/envs/fastgl5/lib/python3.9/site-packages/torch/utils/data/dataset.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     IterableDataset, TensorDataset, StackDataset, ConcatDataset, Subset, MapDataPipe"
     ]
    }
   ],
   "source": [
    "Dataset??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 路径直接加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: no \"view\" rule for type \"image/png\" passed its test case\n",
      "       (for more information, add \"--debug=1\" on the command line)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img_path = \"/home/djk/torch_learning/tudui/hymenoptera_data/train/ants/0013035.jpg\"        \n",
    "img = Image.open(img_path)\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Dataset加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\n",
      "121\n",
      "245\n",
      "label： bees\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: no \"view\" rule for type \"image/png\" passed its test case\n",
      "       (for more information, add \"--debug=1\" on the command line)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "class MyData(Dataset):     \n",
    "    def __init__(self,root_dir,label_dir):    # 该魔术方法当创建一个事例对象时，会自动调用该函数\n",
    "        self.root_dir = root_dir # self.root_dir 相当于类中的全局变量\n",
    "        self.label_dir = label_dir     \n",
    "        self.path = os.path.join(self.root_dir,self.label_dir) # 字符串拼接，根据是Windows或Lixus系统情况进行拼接               \n",
    "        self.img_path = os.listdir(self.path) # 获得路径下所有图片的地址\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        img_name = self.img_path[idx]\n",
    "        img_item_path = os.path.join(self.root_dir,self.label_dir,img_name)            \n",
    "        img = Image.open(img_item_path)\n",
    "        label = self.label_dir\n",
    "        return img, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_path)\n",
    "    \n",
    "root_dir = \"../hymenoptera_data/train\"\n",
    "ants_label_dir = \"ants\"\n",
    "bees_label_dir = \"bees\"\n",
    "ants_dataset = MyData(root_dir, ants_label_dir)\n",
    "bees_dataset = MyData(root_dir, bees_label_dir)\n",
    "print(len(ants_dataset))\n",
    "print(len(bees_dataset))\n",
    "train_dataset = ants_dataset + bees_dataset # train_dataset 就是两个数据集的集合了     \n",
    "print(len(train_dataset))\n",
    "\n",
    "img,label = train_dataset[200]\n",
    "print(\"label：\",label)\n",
    "img.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastgl5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "357.344px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
